{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f54596d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "#plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#3d plotting\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib qt\n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9059d7a",
   "metadata": {},
   "source": [
    "# Load and clean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1678ef58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>range</th>\n",
       "      <th>rating</th>\n",
       "      <th>id_copy</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>pitch_avg</th>\n",
       "      <th>timbre_avg</th>\n",
       "      <th>key_change_percentage</th>\n",
       "      <th>mode_avg</th>\n",
       "      <th>id_copy_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7L5IwfKB6W0tadcSh9wlyH</td>\n",
       "      <td>Ouverture</td>\n",
       "      <td>short_term</td>\n",
       "      <td>5.393939</td>\n",
       "      <td>7L5IwfKB6W0tadcSh9wlyH</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>-19.440</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>129.006</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.95500</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>322173</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.27, 0.58, 0.21, 0.27, 0.18, 0.34, 0.26, 0.0...</td>\n",
       "      <td>[36.4, -140.17, -20.32, -18.11, 13.38, -37.86,...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7L5IwfKB6W0tadcSh9wlyH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0tAZi3X7dUdd7m8OXB8pMA</td>\n",
       "      <td>Shadow</td>\n",
       "      <td>short_term</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>0tAZi3X7dUdd7m8OXB8pMA</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>-15.256</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>170.316</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>558267</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.18, 0.26, 0.64, 0.5, 0.16, 0.26, 0.16, 0.21...</td>\n",
       "      <td>[40.29, -65.03, 29.6, -16.94, 3.88, -26.49, -1...</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0tAZi3X7dUdd7m8OXB8pMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1XMDIKQbV30WJPKLMN6MKv</td>\n",
       "      <td>INSTRUCTION</td>\n",
       "      <td>short_term</td>\n",
       "      <td>4.969697</td>\n",
       "      <td>1XMDIKQbV30WJPKLMN6MKv</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>-12.480</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>145.405</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.38200</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>262733</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.51, 0.26, 0.22, 0.12, 0.12, 0.2, 0.21, 0.39...</td>\n",
       "      <td>[38.23, -65.25, -37.01, -15.68, 9.7, -36.31, 2...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1XMDIKQbV30WJPKLMN6MKv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1XZdwzd8DTDvkjVc0eJ9BI</td>\n",
       "      <td>Wildlife Analysis</td>\n",
       "      <td>short_term</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>1XZdwzd8DTDvkjVc0eJ9BI</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>-31.212</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>79.755</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>75627</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.12, 0.06, 0.43, 0.1, 0.56, 0.08, 0.08, 0.16...</td>\n",
       "      <td>[28.95, -181.05, 81.47, 3.86, 94.46, -38.57, -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1XZdwzd8DTDvkjVc0eJ9BI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f4cKwcKfNiLbQr8x2tZ3C</td>\n",
       "      <td>Melt!</td>\n",
       "      <td>short_term</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>1f4cKwcKfNiLbQr8x2tZ3C</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>-13.059</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>131.037</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.00772</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>214307</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.63, 0.68, 0.49, 0.41, 0.46, 0.5, 0.56, 0.53...</td>\n",
       "      <td>[36.82, 22.73, -62.74, 44.28, 36.1, -56.15, -1...</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1f4cKwcKfNiLbQr8x2tZ3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2OqtZbITDWCFUHAT9fmdin</td>\n",
       "      <td>Choses nouvelles</td>\n",
       "      <td>long_term</td>\n",
       "      <td>4.242424</td>\n",
       "      <td>2OqtZbITDWCFUHAT9fmdin</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>-12.993</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>140.011</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>234600</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.36, 0.36, 0.31, 0.19, 0.24, 0.25, 0.45, 0.2...</td>\n",
       "      <td>[42.33, -84.86, -38.32, -18.36, -1.64, -23.54,...</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2OqtZbITDWCFUHAT9fmdin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>6EPRKhUOdiFSQwGBRBbvsZ</td>\n",
       "      <td>Ace of Spades</td>\n",
       "      <td>long_term</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>6EPRKhUOdiFSQwGBRBbvsZ</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>-7.748</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>140.452</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>166360</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.31, 0.43, 0.34, 0.66, 0.67, 0.54, 0.46, 0.3...</td>\n",
       "      <td>[51.29, 89.0, 28.24, -10.6, 3.43, -30.31, -2.3...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6EPRKhUOdiFSQwGBRBbvsZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4Jj8pWRyVjh0KIJLrcreRa</td>\n",
       "      <td>Here We Go Jack</td>\n",
       "      <td>long_term</td>\n",
       "      <td>4.121212</td>\n",
       "      <td>4Jj8pWRyVjh0KIJLrcreRa</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>-10.606</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>163.979</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.58500</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>237938</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.29, 0.49, 0.36, 0.16, 0.52, 0.21, 0.28, 0.1...</td>\n",
       "      <td>[41.27, -87.94, -54.71, -3.61, 1.01, -23.17, 4...</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4Jj8pWRyVjh0KIJLrcreRa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>3v9g8iM3v5irWQHqFWaDSo</td>\n",
       "      <td>Cómo Te Quiero</td>\n",
       "      <td>long_term</td>\n",
       "      <td>4.060606</td>\n",
       "      <td>3v9g8iM3v5irWQHqFWaDSo</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>-11.917</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>126.501</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.62200</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>242536</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.32, 0.22, 0.24, 0.16, 0.39, 0.14, 0.23, 0.4...</td>\n",
       "      <td>[40.47, -62.61, 3.05, -1.31, -12.6, -24.89, -1...</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3v9g8iM3v5irWQHqFWaDSo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2tObQO8pxckNOezskTjWVK</td>\n",
       "      <td>Concerto in D Minor, BWV 974: II. Adagio</td>\n",
       "      <td>long_term</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2tObQO8pxckNOezskTjWVK</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>-30.931</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>63.586</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>250333</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.21, 0.28, 0.4, 0.14, 0.38, 0.36, 0.12, 0.31...</td>\n",
       "      <td>[23.88, -124.16, 36.2, 23.86, 83.74, -33.15, 5...</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2tObQO8pxckNOezskTjWVK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                      name  \\\n",
       "0    7L5IwfKB6W0tadcSh9wlyH                                 Ouverture   \n",
       "1    0tAZi3X7dUdd7m8OXB8pMA                                    Shadow   \n",
       "2    1XMDIKQbV30WJPKLMN6MKv                               INSTRUCTION   \n",
       "3    1XZdwzd8DTDvkjVc0eJ9BI                         Wildlife Analysis   \n",
       "4    1f4cKwcKfNiLbQr8x2tZ3C                                     Melt!   \n",
       "..                      ...                                       ...   \n",
       "233  2OqtZbITDWCFUHAT9fmdin                          Choses nouvelles   \n",
       "234  6EPRKhUOdiFSQwGBRBbvsZ                             Ace of Spades   \n",
       "235  4Jj8pWRyVjh0KIJLrcreRa                           Here We Go Jack   \n",
       "236  3v9g8iM3v5irWQHqFWaDSo                            Cómo Te Quiero   \n",
       "237  2tObQO8pxckNOezskTjWVK  Concerto in D Minor, BWV 974: II. Adagio   \n",
       "\n",
       "          range    rating                 id_copy  energy  danceability  \\\n",
       "0    short_term  5.393939  7L5IwfKB6W0tadcSh9wlyH  0.3360        0.4960   \n",
       "1    short_term  5.272727  0tAZi3X7dUdd7m8OXB8pMA  0.2750        0.0832   \n",
       "2    short_term  4.969697  1XMDIKQbV30WJPKLMN6MKv  0.3550        0.4910   \n",
       "3    short_term  4.909091  1XZdwzd8DTDvkjVc0eJ9BI  0.0204        0.1550   \n",
       "4    short_term  4.848485  1f4cKwcKfNiLbQr8x2tZ3C  0.9190        0.7850   \n",
       "..          ...       ...                     ...     ...           ...   \n",
       "233   long_term  4.242424  2OqtZbITDWCFUHAT9fmdin  0.3830        0.6690   \n",
       "234   long_term  4.181818  6EPRKhUOdiFSQwGBRBbvsZ  0.9100        0.3420   \n",
       "235   long_term  4.121212  4Jj8pWRyVjh0KIJLrcreRa  0.3090        0.6790   \n",
       "236   long_term  4.060606  3v9g8iM3v5irWQHqFWaDSo  0.2770        0.6080   \n",
       "237   long_term  4.000000  2tObQO8pxckNOezskTjWVK  0.0179        0.3830   \n",
       "\n",
       "     loudness  valence    tempo  speechiness  acousticness  instrumentalness  \\\n",
       "0     -19.440   0.1850  129.006       0.0513       0.95500          0.912000   \n",
       "1     -15.256   0.0334  170.316       0.0347       0.88700          0.853000   \n",
       "2     -12.480   0.0369  145.405       0.0354       0.38200          0.887000   \n",
       "3     -31.212   0.2780   79.755       0.0462       0.99500          0.936000   \n",
       "4     -13.059   0.4430  131.037       0.0552       0.00772          0.916000   \n",
       "..        ...      ...      ...          ...           ...               ...   \n",
       "233   -12.993   0.5690  140.011       0.0385       0.46500          0.856000   \n",
       "234    -7.748   0.5470  140.452       0.0758       0.00004          0.000121   \n",
       "235   -10.606   0.4730  163.979       0.0320       0.58500          0.907000   \n",
       "236   -11.917   0.4370  126.501       0.0282       0.62200          0.896000   \n",
       "237   -30.931   0.0387   63.586       0.0455       0.99300          0.949000   \n",
       "\n",
       "     duration_ms  time_signature  \\\n",
       "0         322173               4   \n",
       "1         558267               1   \n",
       "2         262733               4   \n",
       "3          75627               4   \n",
       "4         214307               4   \n",
       "..           ...             ...   \n",
       "233       234600               4   \n",
       "234       166360               4   \n",
       "235       237938               4   \n",
       "236       242536               4   \n",
       "237       250333               4   \n",
       "\n",
       "                                             pitch_avg  \\\n",
       "0    [0.27, 0.58, 0.21, 0.27, 0.18, 0.34, 0.26, 0.0...   \n",
       "1    [0.18, 0.26, 0.64, 0.5, 0.16, 0.26, 0.16, 0.21...   \n",
       "2    [0.51, 0.26, 0.22, 0.12, 0.12, 0.2, 0.21, 0.39...   \n",
       "3    [0.12, 0.06, 0.43, 0.1, 0.56, 0.08, 0.08, 0.16...   \n",
       "4    [0.63, 0.68, 0.49, 0.41, 0.46, 0.5, 0.56, 0.53...   \n",
       "..                                                 ...   \n",
       "233  [0.36, 0.36, 0.31, 0.19, 0.24, 0.25, 0.45, 0.2...   \n",
       "234  [0.31, 0.43, 0.34, 0.66, 0.67, 0.54, 0.46, 0.3...   \n",
       "235  [0.29, 0.49, 0.36, 0.16, 0.52, 0.21, 0.28, 0.1...   \n",
       "236  [0.32, 0.22, 0.24, 0.16, 0.39, 0.14, 0.23, 0.4...   \n",
       "237  [0.21, 0.28, 0.4, 0.14, 0.38, 0.36, 0.12, 0.31...   \n",
       "\n",
       "                                            timbre_avg  key_change_percentage  \\\n",
       "0    [36.4, -140.17, -20.32, -18.11, 13.38, -37.86,...              75.000000   \n",
       "1    [40.29, -65.03, 29.6, -16.94, 3.88, -26.49, -1...              93.333333   \n",
       "2    [38.23, -65.25, -37.01, -15.68, 9.7, -36.31, 2...              75.000000   \n",
       "3    [28.95, -181.05, 81.47, 3.86, 94.46, -38.57, -...               0.000000   \n",
       "4    [36.82, 22.73, -62.74, 44.28, 36.1, -56.15, -1...              85.714286   \n",
       "..                                                 ...                    ...   \n",
       "233  [42.33, -84.86, -38.32, -18.36, -1.64, -23.54,...              90.909091   \n",
       "234  [51.29, 89.0, 28.24, -10.6, 3.43, -30.31, -2.3...              80.000000   \n",
       "235  [41.27, -87.94, -54.71, -3.61, 1.01, -23.17, 4...              87.500000   \n",
       "236  [40.47, -62.61, 3.05, -1.31, -12.6, -24.89, -1...              88.888889   \n",
       "237  [23.88, -124.16, 36.2, 23.86, 83.74, -33.15, 5...              66.666667   \n",
       "\n",
       "     mode_avg               id_copy_2  \n",
       "0        0.14  7L5IwfKB6W0tadcSh9wlyH  \n",
       "1        0.86  0tAZi3X7dUdd7m8OXB8pMA  \n",
       "2        0.36  1XMDIKQbV30WJPKLMN6MKv  \n",
       "3        0.33  1XZdwzd8DTDvkjVc0eJ9BI  \n",
       "4        0.56  1f4cKwcKfNiLbQr8x2tZ3C  \n",
       "..        ...                     ...  \n",
       "233      0.45  2OqtZbITDWCFUHAT9fmdin  \n",
       "234      0.50  6EPRKhUOdiFSQwGBRBbvsZ  \n",
       "235      0.75  4Jj8pWRyVjh0KIJLrcreRa  \n",
       "236      0.73  3v9g8iM3v5irWQHqFWaDSo  \n",
       "237      0.43  2tObQO8pxckNOezskTjWVK  \n",
       "\n",
       "[238 rows x 20 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toptracks_features_analysis = pd.read_csv(\"./dataset/toptracks_ratings_features_analysis.csv\")\n",
    "df_toptracks_features_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0eb8838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row of features: ['Ouverture' 0.336 0.496 -19.44 0.185 129.006 0.0513 0.955 0.912 322173 4\n",
      " '[0.27, 0.58, 0.21, 0.27, 0.18, 0.34, 0.26, 0.07, 0.08, 0.27, 0.57, 0.19]'\n",
      " '[36.4, -140.17, -20.32, -18.11, 13.38, -37.86, 3.36, 1.33, -6.62, 3.97, -0.23, 9.65]'\n",
      " 75.0 0.14]\n",
      "(238, 15)\n",
      "\n",
      "\n",
      "my classes: ['bad' 'fine' 'good' 'great']\n",
      "(4,)\n",
      "\n",
      "\n",
      "my labels: [2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(238,)\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe rows into arrays. Every array in the 2d array is a row\n",
    "features = df_toptracks_features_analysis[\n",
    "    [\"name\", \"energy\", \"danceability\", \"loudness\", \"valence\", \"tempo\", \n",
    "     \"speechiness\", \"acousticness\", \"instrumentalness\", \"duration_ms\", \"time_signature\", \n",
    "    \"pitch_avg\", \"timbre_avg\", \"key_change_percentage\", \"mode_avg\"]].to_numpy()\n",
    "\n",
    "# my 5 classes\n",
    "classes = np.array([\"bad\", \"fine\", \"good\", \"great\"])\n",
    "numb_classes = len(classes)\n",
    "\n",
    "# convert all ratings from 0 - 10 into 0 - 4, to match the classes\n",
    "labels = df_toptracks_features_analysis[\"rating\"].to_numpy()\n",
    "labels = np.round([label/10*(numb_classes-1) for label in labels]).astype(\"int\")\n",
    "\n",
    "print(\"first row of features:\", features[0])\n",
    "print(features.shape)\n",
    "print(\"\\n\")\n",
    "print(\"my classes:\", classes)\n",
    "print(classes.shape)\n",
    "print(\"\\n\")\n",
    "print(\"my labels:\", labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "515b2a39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0.336, 0.496, -19.44, 0.185, 129.006, 0.0513, 0.955, 0.912,\n",
       "       322173, 4,\n",
       "       '[0.27, 0.58, 0.21, 0.27, 0.18, 0.34, 0.26, 0.07, 0.08, 0.27, 0.57, 0.19]',\n",
       "       '[36.4, -140.17, -20.32, -18.11, 13.38, -37.86, 3.36, 1.33, -6.62, 3.97, -0.23, 9.65]',\n",
       "       75.0, 0.14], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cleaned = features\n",
    "\n",
    "# Substitute titles with integers\n",
    "for i in range(features_cleaned.shape[0]):\n",
    "    features_cleaned[i][0] = i\n",
    "\n",
    "features_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6ce98db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0.336 0.496 -19.44 0.185 129.006 0.0513 0.955 0.912 322173 4\n",
      " list([0.27, 0.58, 0.21, 0.27, 0.18, 0.34, 0.26, 0.07, 0.08, 0.27, 0.57, 0.19])\n",
      " list([36.4, -140.17, -20.32, -18.11, 13.38, -37.86, 3.36, 1.33, -6.62, 3.97, -0.23, 9.65])\n",
      " 75.0 0.14]\n"
     ]
    }
   ],
   "source": [
    "# convert the timbre and pitch vectors, which are actually strings in the dataframe imported, to lists again\n",
    "for row in range(features_cleaned.shape[0]):\n",
    "    for col in range(features_cleaned.shape[1]):\n",
    "        if type(features_cleaned[row][col]) == str:\n",
    "            features_cleaned[row][col] = ast.literal_eval(features_cleaned[row][col])\n",
    "\n",
    "print(features_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a627482d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 37)\n",
      "[ 0.00000e+00  3.36000e-01  4.96000e-01 -1.94400e+01  1.85000e-01\n",
      "  1.29006e+02  5.13000e-02  9.55000e-01  9.12000e-01  3.22173e+05\n",
      "  4.00000e+00  2.70000e-01  5.80000e-01  2.10000e-01  2.70000e-01\n",
      "  1.80000e-01  3.40000e-01  2.60000e-01  7.00000e-02  8.00000e-02\n",
      "  2.70000e-01  5.70000e-01  1.90000e-01  3.64000e+01 -1.40170e+02\n",
      " -2.03200e+01 -1.81100e+01  1.33800e+01 -3.78600e+01  3.36000e+00\n",
      "  1.33000e+00 -6.62000e+00  3.97000e+00 -2.30000e-01  9.65000e+00\n",
      "  7.50000e+01  1.40000e-01]\n"
     ]
    }
   ],
   "source": [
    "# unpack/flatten the timbre and pitch lists within the 2d features_cleaned\n",
    "# (and subesequently extent the coloumn size of the feature array.)\n",
    "\n",
    "def flatten(x):\n",
    "    for item in x:\n",
    "        try:\n",
    "            #if x has a member (item) it means its a a list or array, therefore we feed the item back into the function.\n",
    "            yield from flatten(item)\n",
    "        #so if x has no members to iterate on (i.e its a float or integer), we return it (yield)\n",
    "        except TypeError:\n",
    "            yield item\n",
    "\n",
    "temp_features = np.empty([])\n",
    "for i in range(features_cleaned.shape[0]):\n",
    "    \n",
    "    # flatten row\n",
    "    row = list(flatten(features_cleaned[i]))\n",
    "    \n",
    "    # round all values in row to 2 decimals max\n",
    "    #row = [round(elem, 2) for elem in row]\n",
    "    \n",
    "    # make numpy array of row\n",
    "    row = np.array(row)\n",
    "    \n",
    "    # add them together\n",
    "    if i == 0:\n",
    "        temp_features = row\n",
    "    else:\n",
    "        temp_features = np.vstack((temp_features, row))\n",
    "\n",
    "# add to final variable\n",
    "features_cleaned = temp_features\n",
    "\n",
    "print(features_cleaned.shape)\n",
    "print(features_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad81e2c",
   "metadata": {},
   "source": [
    "# Create pipeline\n",
    "The best result of the grid search was:\n",
    "\n",
    "* LDA, 5 classes, all features, kfold(5, 100). {'activation': 'identity', 'hidden_layer_sizes': [100, 50, 30], 'max_iter': 1000}. Accuracy = 0.58\n",
    "* LDA, 4 classes, all features, kfold(5,100). {'activation': 'identity', 'hidden_layer_sizes': [100, 100, 50, 50], 'max_iter': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "53895d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=([100, 100, 50, 50]), max_iter=1000, activation='identity')\n",
    "\n",
    "svm = sklearn.svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', LinearDiscriminantAnalysis()),\n",
    "        ('classifier', mlp)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "160cf1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.model_seblection import train_test_split\n",
    "\n",
    "#feat_train, feat_test, lab_train, lab_test = train_test_split(features_cleaned, labels, test_size=0.2, random_state=10)\n",
    "\n",
    "#creating scaling object\n",
    "#scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "#learning scaling from train set\n",
    "#scaler.fit(feat_train)\n",
    "\n",
    "#applying scaling to both train and test set\n",
    "#feat_train = scaler.transform(feat_train)\n",
    "#feat_test = scaler.transform(feat_test)\n",
    "\n",
    "#displaying the size of the original and extended arrays\n",
    "#print(feat_train.shape)\n",
    "#print(lab_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97211be5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.17622662, 0.14474368, 0.18067861, 0.18970132, 0.18251395,\n",
      "       0.17253828, 0.16555762, 0.17951941, 0.18914533, 0.17353702,\n",
      "       0.17461109, 0.09773993, 0.09973407, 0.19012475, 0.21941352,\n",
      "       0.21477818, 0.17666173, 0.19148874, 0.1994338 , 0.0817821 ,\n",
      "       0.0977385 , 0.10785508, 0.21741915, 0.17064929, 0.09175515,\n",
      "       0.17253852, 0.17852259, 0.16676235, 0.09873605, 0.17652774,\n",
      "       0.10372353, 0.17154503, 0.16459298, 0.177526  , 0.09275222,\n",
      "       0.19440198, 0.08277893, 0.18205142, 0.19567251, 0.13429785,\n",
      "       0.18242621, 0.09476328, 0.11741757, 0.09574413, 0.16038036,\n",
      "       0.14062452, 0.09899497, 0.1914885 , 0.09374952, 0.18849659,\n",
      "       0.19747329, 0.16256642, 0.09276485, 0.1785233 , 0.14943767,\n",
      "       0.08860517, 0.19242835, 0.18949318, 0.19434309, 0.07998967,\n",
      "       0.17858338, 0.13962603, 0.12865472, 0.09058428, 0.14256239,\n",
      "       0.08375597, 0.1944797 , 0.15159488, 0.10472155, 0.17223668,\n",
      "       0.19768763, 0.1575799 , 0.1027267 , 0.18504882, 0.17154241,\n",
      "       0.20840573, 0.18650079, 0.14717197, 0.09045482, 0.15854359,\n",
      "       0.16655469, 0.17419505, 0.15572286, 0.18749857, 0.1914885 ,\n",
      "       0.19747233, 0.21650672, 0.18346429, 0.1840961 , 0.08794737,\n",
      "       0.18749738, 0.09474707, 0.18351078, 0.18491364, 0.22484708,\n",
      "       0.20000315, 0.10568357, 0.10981417, 0.21143436, 0.09172082,\n",
      "       0.18945885, 0.08682656, 0.180897  , 0.1126895 , 0.17549801,\n",
      "       0.20814514, 0.08376598, 0.18417645, 0.1659677 , 0.20086384,\n",
      "       0.18247128, 0.11278605, 0.18351126, 0.08676839, 0.19448018,\n",
      "       0.10571837, 0.07783651, 0.18256044, 0.09674096, 0.20245814,\n",
      "       0.09081149, 0.18749833, 0.09663081, 0.2014606 , 0.08673525,\n",
      "       0.21841669, 0.10272551, 0.19547939, 0.10276937, 0.1912632 ,\n",
      "       0.23433423, 0.16456056, 0.15853786, 0.15458751, 0.17168808,\n",
      "       0.19675255, 0.21143699, 0.18646812, 0.09286404, 0.10896659,\n",
      "       0.18401599, 0.18151593, 0.11768603, 0.07880998, 0.14467525,\n",
      "       0.18450642, 0.07180953, 0.08976007, 0.08776498, 0.18062735,\n",
      "       0.18351173, 0.20146251, 0.1009202 , 0.10117531, 0.20744491,\n",
      "       0.16258597, 0.09375358, 0.09674239, 0.08930612, 0.18949127,\n",
      "       0.18949199, 0.20544243, 0.08174276, 0.13463879, 0.10578823,\n",
      "       0.20644855, 0.18082643, 0.17409348, 0.10266662, 0.1635623 ,\n",
      "       0.08709908, 0.12168622, 0.21841693, 0.08140612, 0.09674454,\n",
      "       0.11877656, 0.17451954, 0.18654633, 0.17855549, 0.17050815,\n",
      "       0.19946599, 0.16655636, 0.1605711 , 0.1685493 , 0.14760447,\n",
      "       0.15558481, 0.19129133, 0.19562936, 0.16755247, 0.0997045 ,\n",
      "       0.16256642, 0.10007501, 0.07884526, 0.17356324, 0.1693418 ,\n",
      "       0.10771084, 0.17752457, 0.08876324, 0.1795187 , 0.1715405 ,\n",
      "       0.17332816, 0.19348478, 0.11565828, 0.18051767, 0.093714  ,\n",
      "       0.09996891, 0.10071373, 0.19543958, 0.19450331, 0.0927515 ,\n",
      "       0.18458843, 0.12770271, 0.1117022 , 0.19045639, 0.17951894,\n",
      "       0.21941257, 0.1047976 , 0.17760921, 0.20145106, 0.17852211,\n",
      "       0.2254436 , 0.18677568, 0.16655612, 0.20345545, 0.09774041,\n",
      "       0.20245934, 0.12854791, 0.13264585, 0.14760494, 0.17858982,\n",
      "       0.19765329, 0.09234333, 0.10472059, 0.19049144, 0.16912103,\n",
      "       0.16149807, 0.18650126, 0.17851806, 0.17253876, 0.18653655,\n",
      "       0.09275126, 0.19348216, 0.09280539, 0.1183784 , 0.07367325,\n",
      "       0.10771275, 0.09075785, 0.08377624, 0.1884625 , 0.19154954,\n",
      "       0.17948174, 0.08580256, 0.14162254, 0.19846916, 0.23539901,\n",
      "       0.09170341, 0.16954756, 0.20641828, 0.18880272, 0.19944549,\n",
      "       0.21445847, 0.20383954, 0.10919619, 0.20149422, 0.20203638,\n",
      "       0.16452718, 0.09873629, 0.17759132, 0.19146371, 0.09232354,\n",
      "       0.22475481, 0.09774041, 0.20637774, 0.22440124, 0.23022461,\n",
      "       0.2033329 , 0.19485354, 0.20046329, 0.19049048, 0.21242499,\n",
      "       0.20848036, 0.20844316, 0.09773874, 0.18159199, 0.16256571,\n",
      "       0.2174859 , 0.09275055, 0.20230007, 0.09193516, 0.19651008,\n",
      "       0.19939566, 0.10372424, 0.19644117, 0.14155364, 0.17154121,\n",
      "       0.08705854, 0.19253945, 0.22445798, 0.12431765, 0.10272503,\n",
      "       0.19747233, 0.18946624, 0.16256762, 0.10264826, 0.18548441,\n",
      "       0.10571861, 0.10272598, 0.20445514, 0.22538185, 0.18367434,\n",
      "       0.11842203, 0.20776772, 0.1875968 , 0.1974535 , 0.1944809 ,\n",
      "       0.08377695, 0.21994042, 0.21704149, 0.22042489, 0.1896317 ,\n",
      "       0.18140435, 0.1914885 , 0.21046877, 0.09438229, 0.11811018,\n",
      "       0.23739839, 0.22224569, 0.09641314, 0.19361329, 0.18949294,\n",
      "       0.17154026, 0.2119956 , 0.21909785, 0.21777439, 0.19756866,\n",
      "       0.22439981, 0.20539498, 0.20193672, 0.10867333, 0.20043206,\n",
      "       0.120713  , 0.2311635 , 0.09018731, 0.10269403, 0.16555858,\n",
      "       0.17655659, 0.1899693 , 0.09959817, 0.10372424, 0.1007309 ,\n",
      "       0.22127986, 0.15653658, 0.11304021, 0.16155291, 0.18450546,\n",
      "       0.19049001, 0.23040652, 0.19338751, 0.19248581, 0.21442509,\n",
      "       0.19932079, 0.17434525, 0.19448161, 0.17250514, 0.19747138,\n",
      "       0.09179449, 0.20027518, 0.09773922, 0.22440243, 0.22041106,\n",
      "       0.22838902, 0.18211055, 0.09280562, 0.16057301, 0.18949342,\n",
      "       0.21930504, 0.16751838, 0.10272622, 0.1852212 , 0.19048882,\n",
      "       0.17852545, 0.21243   , 0.21342945, 0.18515372, 0.17655659,\n",
      "       0.17171288, 0.15462422, 0.22739291, 0.19462276, 0.17253971,\n",
      "       0.1855247 , 0.18783665, 0.10978866, 0.20245767, 0.19847012,\n",
      "       0.09474635, 0.17453361, 0.21143484, 0.18057513, 0.15957451,\n",
      "       0.22041321, 0.07784247, 0.18580937, 0.19774032, 0.25633097,\n",
      "       0.19148088, 0.11971188, 0.20146084, 0.12259412, 0.10072994,\n",
      "       0.09933949, 0.20349121, 0.10269451, 0.21542597, 0.1765275 ,\n",
      "       0.22844529, 0.17549706, 0.08377624, 0.10767198, 0.22112465,\n",
      "       0.22391367, 0.20444036, 0.09674072, 0.10925722, 0.1939652 ,\n",
      "       0.19248581, 0.19547749, 0.20445275, 0.10771203, 0.0852561 ,\n",
      "       0.17253852, 0.09562826, 0.18924594, 0.20296907, 0.18457246,\n",
      "       0.17051077, 0.1795435 , 0.10271549, 0.21941185, 0.20299411,\n",
      "       0.15476704, 0.18251204, 0.09474564, 0.21143675, 0.10269165,\n",
      "       0.09275126, 0.20030761, 0.19020176, 0.20154595, 0.09979391,\n",
      "       0.10571814, 0.20744419, 0.10263157, 0.20445323, 0.17852378,\n",
      "       0.19931412, 0.15558505, 0.16656923, 0.16456151, 0.09873819,\n",
      "       0.19348264, 0.20744705, 0.1961267 , 0.22636342, 0.21438003,\n",
      "       0.1914556 , 0.20146132, 0.20741272, 0.18247938, 0.19846964,\n",
      "       0.20249748, 0.2393291 , 0.1972127 , 0.19048834, 0.20943904,\n",
      "       0.22211432, 0.09175563, 0.11269808, 0.20644832, 0.22838902,\n",
      "       0.10368896, 0.18650198, 0.18973041, 0.22141051, 0.16751838,\n",
      "       0.18849945, 0.2003665 , 0.19510579, 0.1584599 , 0.0964179 ,\n",
      "       0.10222816, 0.18550444, 0.21342969, 0.14557338, 0.21745038,\n",
      "       0.19858623, 0.1084621 , 0.22538209, 0.19943261, 0.21941257]), 'score_time': array([0.00099707, 0.00099754, 0.00191474, 0.00199413, 0.00199294,\n",
      "       0.00099969, 0.00103068, 0.00202942, 0.00103188, 0.00099611,\n",
      "       0.00199509, 0.00099707, 0.00199461, 0.00198746, 0.00199819,\n",
      "       0.00099659, 0.00299263, 0.00199366, 0.00191545, 0.00099683,\n",
      "       0.00199556, 0.00185204, 0.0009973 , 0.00192642, 0.00099802,\n",
      "       0.00099659, 0.00199533, 0.00199485, 0.00199533, 0.00099754,\n",
      "       0.00099659, 0.00199032, 0.00196075, 0.00199437, 0.00199413,\n",
      "       0.00099754, 0.00199389, 0.00253892, 0.00195336, 0.00199437,\n",
      "       0.00178337, 0.00197792, 0.0019021 , 0.00199485, 0.00192046,\n",
      "       0.00299144, 0.00199437, 0.00199413, 0.00199556, 0.00202894,\n",
      "       0.00299168, 0.00199366, 0.0019815 , 0.00199389, 0.00099778,\n",
      "       0.00299144, 0.00299144, 0.0009973 , 0.0009973 , 0.00094581,\n",
      "       0.00193191, 0.00199533, 0.00199437, 0.00199342, 0.00196409,\n",
      "       0.00199652, 0.00199389, 0.00099897, 0.00199461, 0.00243592,\n",
      "       0.00096464, 0.00202656, 0.00199413, 0.00093031, 0.00199318,\n",
      "       0.00099802, 0.00199485, 0.00199389, 0.0010283 , 0.00099826,\n",
      "       0.00099802, 0.00202775, 0.00096488, 0.00099683, 0.00199533,\n",
      "       0.00199628, 0.00096464, 0.00299168, 0.00199509, 0.00193644,\n",
      "       0.0030272 , 0.00199437, 0.00199461, 0.00199389, 0.00200438,\n",
      "       0.00099945, 0.0009985 , 0.00188875, 0.00203323, 0.00102258,\n",
      "       0.00199628, 0.00193787, 0.00193119, 0.00199604, 0.00199628,\n",
      "       0.00104928, 0.00099778, 0.00199533, 0.00099921, 0.00202703,\n",
      "       0.00236225, 0.00190759, 0.00099492, 0.00249505, 0.00099683,\n",
      "       0.00099659, 0.00195146, 0.00194645, 0.00199318, 0.00099778,\n",
      "       0.00194025, 0.00203228, 0.00194979, 0.00103283, 0.00099683,\n",
      "       0.00099707, 0.00199413, 0.00199389, 0.0019927 , 0.00210977,\n",
      "       0.00099778, 0.00101686, 0.00299144, 0.00099683, 0.00099778,\n",
      "       0.00199389, 0.00202703, 0.00202966, 0.00299573, 0.00198221,\n",
      "       0.00099707, 0.00099587, 0.00099707, 0.00197387, 0.00193357,\n",
      "       0.00199461, 0.0029912 , 0.00199389, 0.00199318, 0.00188398,\n",
      "       0.00099468, 0.00102973, 0.00099754, 0.00099921, 0.00099635,\n",
      "       0.00194263, 0.00199008, 0.00099635, 0.00199294, 0.00194573,\n",
      "       0.00299263, 0.00200415, 0.00099945, 0.00199413, 0.00092697,\n",
      "       0.00202775, 0.00199413, 0.00310063, 0.0019958 , 0.0019629 ,\n",
      "       0.00195265, 0.00198245, 0.00199389, 0.00282764, 0.00099587,\n",
      "       0.00190091, 0.00199461, 0.00297403, 0.00200129, 0.00202775,\n",
      "       0.00099754, 0.00228977, 0.00099707, 0.00199461, 0.00199485,\n",
      "       0.00099778, 0.00195622, 0.00199389, 0.00203538, 0.00099587,\n",
      "       0.00199294, 0.00099707, 0.00199389, 0.00099969, 0.00199461,\n",
      "       0.00199699, 0.00102377, 0.00099754, 0.00202942, 0.0019958 ,\n",
      "       0.00196671, 0.00099659, 0.00199389, 0.00199628, 0.00099874,\n",
      "       0.00193119, 0.00194955, 0.00299191, 0.00200462, 0.00099659,\n",
      "       0.00191307, 0.00195026, 0.00199533, 0.00099897, 0.00099611,\n",
      "       0.00099754, 0.00191855, 0.00190878, 0.00099683, 0.00199676,\n",
      "       0.0009973 , 0.00199318, 0.00299025, 0.00199485, 0.00199389,\n",
      "       0.00199437, 0.00199437, 0.00199461, 0.00199509, 0.00092912,\n",
      "       0.00099635, 0.00199389, 0.0009973 , 0.00199366, 0.00199461,\n",
      "       0.00199437, 0.00099754, 0.0009973 , 0.00199461, 0.0029583 ,\n",
      "       0.00099826, 0.00099826, 0.00194097, 0.00199485, 0.0009973 ,\n",
      "       0.00199556, 0.00099897, 0.00199485, 0.00199461, 0.0009377 ,\n",
      "       0.00201869, 0.00196147, 0.00199437, 0.00199437, 0.00097036,\n",
      "       0.00199366, 0.00099897, 0.00202346, 0.00195193, 0.00199461,\n",
      "       0.0009656 , 0.0009973 , 0.00199246, 0.00096416, 0.00202632,\n",
      "       0.00199676, 0.00299048, 0.00192881, 0.00198555, 0.00341344,\n",
      "       0.00199509, 0.00199223, 0.00199342, 0.00202656, 0.00190639,\n",
      "       0.00199556, 0.00099683, 0.00199485, 0.00199485, 0.00199413,\n",
      "       0.00099683, 0.00199461, 0.00199389, 0.00191736, 0.00199366,\n",
      "       0.00192785, 0.00202966, 0.00203013, 0.00099111, 0.00295973,\n",
      "       0.0025425 , 0.00195479, 0.00199413, 0.00199509, 0.00199485,\n",
      "       0.00099659, 0.00199556, 0.00193644, 0.00202823, 0.00199676,\n",
      "       0.00099707, 0.00099921, 0.00196075, 0.00199246, 0.00199485,\n",
      "       0.00099683, 0.00199413, 0.00218129, 0.00199485, 0.00188684,\n",
      "       0.0019958 , 0.00199413, 0.00189614, 0.00164223, 0.00199294,\n",
      "       0.00199437, 0.00199461, 0.00199413, 0.00199437, 0.00202775,\n",
      "       0.00099754, 0.00199485, 0.0009656 , 0.00186729, 0.00199652,\n",
      "       0.00096488, 0.00102782, 0.00199342, 0.00186253, 0.00099778,\n",
      "       0.00214958, 0.0009973 , 0.00100088, 0.00203252, 0.00186563,\n",
      "       0.00096703, 0.00199461, 0.00194216, 0.00199461, 0.00199342,\n",
      "       0.0019176 , 0.0009973 , 0.0019958 , 0.00199437, 0.00199556,\n",
      "       0.00096917, 0.00199604, 0.00199413, 0.00199556, 0.00199604,\n",
      "       0.00101805, 0.00099707, 0.00199461, 0.00099707, 0.00099635,\n",
      "       0.00199461, 0.00197053, 0.00199413, 0.0019958 , 0.00203037,\n",
      "       0.00299096, 0.00192332, 0.00099635, 0.00299191, 0.00199437,\n",
      "       0.00301003, 0.00194907, 0.00199413, 0.00199437, 0.00096679,\n",
      "       0.00096631, 0.00200248, 0.00199437, 0.00199294, 0.00099802,\n",
      "       0.00197482, 0.00199699, 0.0019958 , 0.00199389, 0.00099707,\n",
      "       0.00298929, 0.00199485, 0.0009973 , 0.00099611, 0.00199366,\n",
      "       0.00195909, 0.00095987, 0.00199437, 0.00099754, 0.00299025,\n",
      "       0.00197554, 0.00099754, 0.00099683, 0.00099707, 0.00096273,\n",
      "       0.00199389, 0.00099754, 0.00202751, 0.00190163, 0.00199366,\n",
      "       0.00099659, 0.00194335, 0.00199342, 0.00302601, 0.00197816,\n",
      "       0.00200272, 0.00196266, 0.00299144, 0.0019927 , 0.00099874,\n",
      "       0.00199723, 0.00096297, 0.00199318, 0.00199366, 0.00199795,\n",
      "       0.00197458, 0.00199485, 0.00099921, 0.00199413, 0.00204754,\n",
      "       0.00198579, 0.00200796, 0.00099659, 0.00199294, 0.00199389,\n",
      "       0.00199413, 0.00199437, 0.00199533, 0.00099611, 0.00199533,\n",
      "       0.00099754, 0.00199461, 0.00199461, 0.00199389, 0.0019629 ,\n",
      "       0.00103021, 0.00097227, 0.0009737 , 0.00202918, 0.00199342,\n",
      "       0.0009973 , 0.00199676, 0.00199366, 0.0020268 , 0.00099707,\n",
      "       0.00195909, 0.00201988, 0.00293374, 0.0019412 , 0.00189972,\n",
      "       0.00199413, 0.00099802, 0.00299382, 0.00201035, 0.00299048,\n",
      "       0.00199437, 0.00201392, 0.00198007, 0.00099611, 0.00096202,\n",
      "       0.00199604, 0.00102401, 0.00196147, 0.00099754, 0.00194216,\n",
      "       0.00199461, 0.00299025, 0.00202632, 0.00199437, 0.00099707,\n",
      "       0.00198936, 0.00202751, 0.00199342, 0.00099754, 0.00199461,\n",
      "       0.00099707, 0.00202799, 0.00099683, 0.00199342, 0.0020287 ,\n",
      "       0.00099897, 0.00199437, 0.00199342, 0.00099516, 0.0019958 ,\n",
      "       0.00199008, 0.00198078, 0.0009973 , 0.0030272 , 0.00199676,\n",
      "       0.00199437, 0.00203037, 0.00199485, 0.00099969, 0.00099969,\n",
      "       0.00099945, 0.00165653, 0.00099611, 0.00199366, 0.00099754]), 'test_f1_macro': array([0.39455128, 0.38862126, 0.3218599 , 0.36572529, 0.30990551,\n",
      "       0.46153846, 0.28021064, 0.35634921, 0.41578576, 0.28684211,\n",
      "       0.43513072, 0.37414895, 0.399729  , 0.33429487, 0.33472222,\n",
      "       0.38614499, 0.25786056, 0.33753071, 0.26832579, 0.51210801,\n",
      "       0.45028772, 0.32546778, 0.25294118, 0.28681319, 0.41300813,\n",
      "       0.21335807, 0.46568627, 0.37520325, 0.24342105, 0.21501926,\n",
      "       0.41146564, 0.2798129 , 0.35248918, 0.23010753, 0.35558968,\n",
      "       0.27134146, 0.36498918, 0.31499702, 0.36928244, 0.21621622,\n",
      "       0.48956421, 0.4766561 , 0.33219697, 0.40394144, 0.27788462,\n",
      "       0.36752137, 0.46483029, 0.46884384, 0.28903904, 0.35952513,\n",
      "       0.39274711, 0.41205784, 0.39073427, 0.36841939, 0.20793651,\n",
      "       0.39307164, 0.32579365, 0.28472222, 0.29927514, 0.26190476,\n",
      "       0.43376068, 0.35083685, 0.36111361, 0.26920996, 0.27838628,\n",
      "       0.2195122 , 0.40853175, 0.28234047, 0.25015015, 0.22327409,\n",
      "       0.46777003, 0.3327381 , 0.31425439, 0.33096822, 0.23669468,\n",
      "       0.43751885, 0.31439394, 0.35497967, 0.41731266, 0.39264307,\n",
      "       0.3840812 , 0.32281746, 0.31121795, 0.39145299, 0.25203252,\n",
      "       0.40319396, 0.31825397, 0.46708826, 0.32083333, 0.27397661,\n",
      "       0.4090812 , 0.38333333, 0.23863636, 0.32820513, 0.26405758,\n",
      "       0.26797386, 0.35987118, 0.45351593, 0.3970399 , 0.29099462,\n",
      "       0.39033189, 0.33097319, 0.39411145, 0.35658939, 0.26190476,\n",
      "       0.37118437, 0.34066986, 0.18108108, 0.48019505, 0.30436508,\n",
      "       0.27683226, 0.34758935, 0.26679842, 0.45225338, 0.27125678,\n",
      "       0.35152985, 0.35732074, 0.23654971, 0.32397661, 0.32051435,\n",
      "       0.39870889, 0.27448405, 0.23276723, 0.55813492, 0.4011918 ,\n",
      "       0.24827868, 0.29839744, 0.38888129, 0.23888889, 0.31738437,\n",
      "       0.35895746, 0.38209627, 0.32675439, 0.23273273, 0.41233766,\n",
      "       0.26980953, 0.54110276, 0.29566792, 0.35517734, 0.35691194,\n",
      "       0.32905983, 0.19647696, 0.29127907, 0.34524261, 0.38462627,\n",
      "       0.25641026, 0.3421748 , 0.45      , 0.36688312, 0.39421922,\n",
      "       0.38427173, 0.40687492, 0.30966037, 0.29179601, 0.32119514,\n",
      "       0.33015873, 0.38059615, 0.39592246, 0.2011655 , 0.36837979,\n",
      "       0.28005211, 0.3069842 , 0.31428571, 0.51669738, 0.3152506 ,\n",
      "       0.32792793, 0.28508772, 0.33785779, 0.35698052, 0.30896281,\n",
      "       0.46678322, 0.31180223, 0.39594017, 0.27232143, 0.34868421,\n",
      "       0.28733583, 0.28246078, 0.32619048, 0.2191311 , 0.41375291,\n",
      "       0.21802326, 0.2097561 , 0.37165992, 0.37106227, 0.24345238,\n",
      "       0.28557222, 0.25      , 0.27222222, 0.31652314, 0.19736015,\n",
      "       0.37206411, 0.20968615, 0.43577075, 0.21747967, 0.44406371,\n",
      "       0.36213705, 0.48967429, 0.41149267, 0.40674603, 0.27752976,\n",
      "       0.45977633, 0.36996245, 0.39621212, 0.32554113, 0.27793342,\n",
      "       0.3123895 , 0.29534413, 0.39247967, 0.30316924, 0.37541406,\n",
      "       0.40769231, 0.40015015, 0.33214286, 0.28669468, 0.4077381 ,\n",
      "       0.24225445, 0.26019022, 0.40972222, 0.31388889, 0.35287115,\n",
      "       0.29406982, 0.43388278, 0.246337  , 0.31621622, 0.36858974,\n",
      "       0.32048676, 0.29758772, 0.35587979, 0.39089267, 0.24391862,\n",
      "       0.1978022 , 0.31868687, 0.2479067 , 0.435747  , 0.47564599,\n",
      "       0.20970696, 0.21944771, 0.32519583, 0.28276993, 0.35073479,\n",
      "       0.32935069, 0.33902384, 0.25609756, 0.31570513, 0.37772657,\n",
      "       0.2839014 , 0.33414634, 0.42125192, 0.33333333, 0.41183261,\n",
      "       0.28671044, 0.40193432, 0.26805556, 0.39150327, 0.35073529,\n",
      "       0.35850202, 0.38585434, 0.28547009, 0.36968816, 0.21203346,\n",
      "       0.26190476, 0.32759872, 0.40708479, 0.36923077, 0.24188312,\n",
      "       0.25313118, 0.51987179, 0.26749639, 0.23525799, 0.35841023,\n",
      "       0.42307692, 0.36959707, 0.24126984, 0.38063178, 0.27872128,\n",
      "       0.27953668, 0.34786822, 0.3047619 , 0.20277778, 0.29545455,\n",
      "       0.21018651, 0.33928826, 0.32359626, 0.35515873, 0.40218729,\n",
      "       0.47301587, 0.4017934 , 0.3406746 , 0.47029499, 0.24242424,\n",
      "       0.30614543, 0.41259398, 0.37460317, 0.3997114 , 0.26045752,\n",
      "       0.37394958, 0.24561966, 0.24358974, 0.26880985, 0.48598331,\n",
      "       0.27284473, 0.32824493, 0.41196694, 0.30018315, 0.35709459,\n",
      "       0.35469269, 0.34809103, 0.32649573, 0.31127125, 0.29980108,\n",
      "       0.39282045, 0.37296176, 0.56086549, 0.34040404, 0.30349548,\n",
      "       0.3065508 , 0.40873016, 0.2827051 , 0.36123693, 0.43715534,\n",
      "       0.42568214, 0.25294442, 0.28233591, 0.36453488, 0.30156049,\n",
      "       0.25187339, 0.30320513, 0.32301051, 0.33623693, 0.40554584,\n",
      "       0.27438718, 0.19100496, 0.47880117, 0.21123188, 0.23412698,\n",
      "       0.36654135, 0.26439142, 0.24662618, 0.38004101, 0.28479822,\n",
      "       0.26253388, 0.39440994, 0.25567301, 0.32142857, 0.24073704,\n",
      "       0.28648091, 0.31300813, 0.23746867, 0.33674374, 0.53870432,\n",
      "       0.38348968, 0.25062657, 0.41810217, 0.29664634, 0.36138478,\n",
      "       0.29761905, 0.28750769, 0.36933286, 0.34421922, 0.39460539,\n",
      "       0.3494857 , 0.34285714, 0.3875    , 0.43860337, 0.19500675,\n",
      "       0.32239382, 0.34337979, 0.27134146, 0.3254889 , 0.42482675,\n",
      "       0.34479009, 0.26944444, 0.43331136, 0.30171395, 0.28383459,\n",
      "       0.32771758, 0.23092105, 0.35479798, 0.31570513, 0.31203096,\n",
      "       0.43909214, 0.24326805, 0.35563456, 0.33182367, 0.44530894,\n",
      "       0.35254804, 0.19060606, 0.37071513, 0.39902402, 0.30176768,\n",
      "       0.26515939, 0.24342105, 0.39723145, 0.33648705, 0.37649573,\n",
      "       0.33904574, 0.2995286 , 0.27512077, 0.37056938, 0.37696459,\n",
      "       0.31136521, 0.29119527, 0.27033327, 0.28071757, 0.4216489 ,\n",
      "       0.27012384, 0.225     , 0.30487013, 0.30428486, 0.35656371,\n",
      "       0.2687247 , 0.39128788, 0.3137202 , 0.31949544, 0.4753386 ,\n",
      "       0.31271645, 0.2561121 , 0.21717172, 0.34207617, 0.43453526,\n",
      "       0.39350314, 0.31819708, 0.28393235, 0.20970696, 0.29861191,\n",
      "       0.23355263, 0.39072053, 0.27620333, 0.25732601, 0.37550813,\n",
      "       0.36036009, 0.34123905, 0.33644783, 0.37912088, 0.40161171,\n",
      "       0.43648112, 0.37515635, 0.27638889, 0.37466863, 0.26872864,\n",
      "       0.43412698, 0.29037227, 0.31976532, 0.22669785, 0.38583039,\n",
      "       0.3731685 , 0.44529499, 0.33513709, 0.43760885, 0.29020695,\n",
      "       0.34285714, 0.25396825, 0.2637202 , 0.45200348, 0.36214734,\n",
      "       0.38264652, 0.29561335, 0.32149877, 0.45511364, 0.35148129,\n",
      "       0.32279972, 0.32222222, 0.40575871, 0.29496505, 0.25064599,\n",
      "       0.27913078, 0.40268661, 0.31527242, 0.35514706, 0.34350649,\n",
      "       0.14920635, 0.30656109, 0.30313118, 0.23295218, 0.36291291,\n",
      "       0.39864719, 0.35178035, 0.25770423, 0.27454659, 0.36923077,\n",
      "       0.30773525, 0.31220238, 0.39312039, 0.28953349, 0.28306233,\n",
      "       0.33106061, 0.21884317, 0.31710526, 0.25914634, 0.37923551,\n",
      "       0.32201132, 0.35810811, 0.35142022, 0.4142316 , 0.17732367,\n",
      "       0.34017453, 0.36181955, 0.2625    , 0.28306233, 0.30876068]), 'train_f1_macro': array([0.63619805, 0.66152789, 0.68260524, 0.64317119, 0.67398467,\n",
      "       0.64800898, 0.64452962, 0.65644227, 0.65503177, 0.64839825,\n",
      "       0.59300129, 0.67292782, 0.63954739, 0.71419384, 0.68767765,\n",
      "       0.67225095, 0.70022212, 0.63926422, 0.66606021, 0.65787027,\n",
      "       0.64603046, 0.70991695, 0.65279913, 0.62262645, 0.69114128,\n",
      "       0.71520386, 0.65296147, 0.63130543, 0.6708072 , 0.60344359,\n",
      "       0.6381323 , 0.69297741, 0.64990122, 0.6223065 , 0.67234455,\n",
      "       0.64764273, 0.66373393, 0.642621  , 0.67583402, 0.68466885,\n",
      "       0.61812031, 0.65005115, 0.70336723, 0.69374845, 0.6645986 ,\n",
      "       0.69090157, 0.63245097, 0.6449118 , 0.64851397, 0.6535594 ,\n",
      "       0.67774658, 0.65335663, 0.65718105, 0.66032151, 0.67384099,\n",
      "       0.66508089, 0.67753775, 0.67108806, 0.70105984, 0.65525935,\n",
      "       0.6725482 , 0.66644714, 0.71067197, 0.63404605, 0.68307707,\n",
      "       0.65862718, 0.65709648, 0.67749966, 0.65276461, 0.69793223,\n",
      "       0.65956436, 0.69236667, 0.62596779, 0.66829004, 0.67411084,\n",
      "       0.73607223, 0.5844182 , 0.67320422, 0.62626741, 0.67920201,\n",
      "       0.62871995, 0.68279725, 0.69888892, 0.61941067, 0.66375564,\n",
      "       0.61811293, 0.61634303, 0.66348541, 0.66787541, 0.66996683,\n",
      "       0.58940062, 0.66164474, 0.66186098, 0.68150548, 0.72140981,\n",
      "       0.68225044, 0.68495192, 0.6425793 , 0.63410069, 0.65510311,\n",
      "       0.65306989, 0.60953091, 0.61731198, 0.65705876, 0.7532827 ,\n",
      "       0.70659056, 0.60874565, 0.67745565, 0.67634727, 0.68597257,\n",
      "       0.63244417, 0.69828526, 0.65574531, 0.66112402, 0.71411995,\n",
      "       0.69062292, 0.59056644, 0.72639662, 0.64336549, 0.67938175,\n",
      "       0.66949549, 0.66681262, 0.70682866, 0.64861075, 0.61929495,\n",
      "       0.68733553, 0.6645444 , 0.6374292 , 0.69482246, 0.64614742,\n",
      "       0.67351475, 0.63447064, 0.63220024, 0.66982691, 0.6426336 ,\n",
      "       0.64530836, 0.6025746 , 0.6769641 , 0.63686885, 0.68079106,\n",
      "       0.63184179, 0.65603653, 0.6721064 , 0.6474898 , 0.66613302,\n",
      "       0.72178428, 0.66645932, 0.62178638, 0.6875497 , 0.63986809,\n",
      "       0.64227002, 0.6387177 , 0.65775814, 0.67548913, 0.61079548,\n",
      "       0.72003392, 0.68923114, 0.66683749, 0.65119387, 0.64640144,\n",
      "       0.6384208 , 0.65854049, 0.699864  , 0.65412791, 0.67499043,\n",
      "       0.68864446, 0.63439793, 0.67471701, 0.67062061, 0.67614321,\n",
      "       0.66490101, 0.65070306, 0.6314693 , 0.67654559, 0.6712563 ,\n",
      "       0.68366292, 0.6347983 , 0.66076153, 0.72054825, 0.65177659,\n",
      "       0.64720655, 0.6929665 , 0.68369518, 0.67786211, 0.61186828,\n",
      "       0.67890312, 0.64753266, 0.66870121, 0.63478162, 0.65294674,\n",
      "       0.67211447, 0.6733323 , 0.6293598 , 0.6886949 , 0.6536891 ,\n",
      "       0.70276599, 0.67921657, 0.64046644, 0.6559871 , 0.64130209,\n",
      "       0.66210536, 0.65639739, 0.69395168, 0.61529389, 0.67229024,\n",
      "       0.66579976, 0.63789276, 0.62368114, 0.6576749 , 0.66841264,\n",
      "       0.64446262, 0.68162719, 0.65828271, 0.71895598, 0.65488522,\n",
      "       0.69232772, 0.67180849, 0.66643577, 0.68163876, 0.652866  ,\n",
      "       0.60890947, 0.64220149, 0.65963888, 0.67710124, 0.65926134,\n",
      "       0.65889052, 0.67726766, 0.65348965, 0.63964208, 0.6685574 ,\n",
      "       0.71101032, 0.69016935, 0.67626096, 0.64474822, 0.63809836,\n",
      "       0.70008276, 0.61308585, 0.65647892, 0.69493464, 0.59371019,\n",
      "       0.66653772, 0.68207973, 0.65696105, 0.62083039, 0.67620038,\n",
      "       0.6277075 , 0.65622088, 0.6744135 , 0.68959887, 0.63609974,\n",
      "       0.67860952, 0.65320293, 0.64336219, 0.62383871, 0.61928647,\n",
      "       0.6474931 , 0.56709936, 0.64434284, 0.6490459 , 0.68337745,\n",
      "       0.66744321, 0.67954862, 0.63901341, 0.64798782, 0.71168676,\n",
      "       0.70149401, 0.62168728, 0.67970455, 0.69497721, 0.58915628,\n",
      "       0.66058927, 0.6747669 , 0.64446821, 0.63153087, 0.62512141,\n",
      "       0.69101458, 0.69879488, 0.68651526, 0.68862573, 0.6341548 ,\n",
      "       0.67660224, 0.66741026, 0.62724007, 0.64013158, 0.6039982 ,\n",
      "       0.65076543, 0.66915273, 0.68118699, 0.64958069, 0.67698747,\n",
      "       0.66404552, 0.59176108, 0.64065463, 0.68306291, 0.71055814,\n",
      "       0.6518743 , 0.65786526, 0.68875812, 0.65196726, 0.63805234,\n",
      "       0.70203215, 0.66129556, 0.64499227, 0.67711591, 0.66758526,\n",
      "       0.67542072, 0.70145308, 0.65126312, 0.63935467, 0.69550372,\n",
      "       0.6461944 , 0.66109315, 0.61914076, 0.67085115, 0.71788103,\n",
      "       0.61058841, 0.68515747, 0.66973862, 0.65819898, 0.66142835,\n",
      "       0.65935307, 0.63345414, 0.66675019, 0.64228932, 0.6274704 ,\n",
      "       0.66135314, 0.64688143, 0.65102753, 0.69074999, 0.64184393,\n",
      "       0.69153226, 0.67734786, 0.61824561, 0.65988994, 0.62728213,\n",
      "       0.63089426, 0.67851197, 0.66934073, 0.66149119, 0.66691246,\n",
      "       0.707045  , 0.66756651, 0.6213831 , 0.66616237, 0.68905535,\n",
      "       0.70741036, 0.64846219, 0.64075995, 0.63878309, 0.60662645,\n",
      "       0.64985806, 0.66395782, 0.66692095, 0.68428265, 0.61828922,\n",
      "       0.6551776 , 0.68501096, 0.62999063, 0.67141486, 0.59927561,\n",
      "       0.64749122, 0.67050602, 0.64284742, 0.64163187, 0.68365715,\n",
      "       0.66907051, 0.65818386, 0.66982776, 0.65493796, 0.62820708,\n",
      "       0.69264988, 0.64364258, 0.60794988, 0.69186673, 0.69237537,\n",
      "       0.66517209, 0.6985976 , 0.66261621, 0.629375  , 0.69260141,\n",
      "       0.70038715, 0.65556912, 0.68065854, 0.68237179, 0.6079791 ,\n",
      "       0.63313679, 0.65474262, 0.65552731, 0.66297892, 0.68176984,\n",
      "       0.64373968, 0.69372827, 0.65776831, 0.66885358, 0.67576362,\n",
      "       0.65214767, 0.70559183, 0.68852544, 0.65957584, 0.66923077,\n",
      "       0.62230172, 0.68324487, 0.6949758 , 0.64007337, 0.60938656,\n",
      "       0.66428071, 0.62852143, 0.67039262, 0.67056363, 0.63383456,\n",
      "       0.66309362, 0.64473684, 0.61236482, 0.63802643, 0.61888508,\n",
      "       0.65609756, 0.66724485, 0.63539767, 0.64398991, 0.67129512,\n",
      "       0.64095346, 0.68214547, 0.66620482, 0.68231594, 0.69242441,\n",
      "       0.67388586, 0.68936601, 0.69610897, 0.65167494, 0.65337978,\n",
      "       0.60827461, 0.63296392, 0.64240887, 0.68903794, 0.66141622,\n",
      "       0.64552404, 0.69934741, 0.66151667, 0.66341665, 0.68461997,\n",
      "       0.68985521, 0.65591728, 0.6144283 , 0.70276053, 0.67010407,\n",
      "       0.69378513, 0.67828526, 0.68048286, 0.63783328, 0.6469248 ,\n",
      "       0.63290345, 0.63779232, 0.68898272, 0.63296958, 0.68332877,\n",
      "       0.70416667, 0.63479639, 0.68305188, 0.61849912, 0.66655707,\n",
      "       0.66970477, 0.68466753, 0.65198257, 0.65212986, 0.63513514,\n",
      "       0.66607678, 0.6959822 , 0.65830999, 0.71192058, 0.65317799,\n",
      "       0.72173125, 0.63230286, 0.65003531, 0.66140019, 0.64166152,\n",
      "       0.62037224, 0.6276557 , 0.7156945 , 0.67949192, 0.69425171,\n",
      "       0.67317494, 0.68051636, 0.62673746, 0.71874203, 0.64626319,\n",
      "       0.63054268, 0.64695408, 0.67641022, 0.60086527, 0.68144232,\n",
      "       0.68136794, 0.64907543, 0.65296683, 0.60415023, 0.67510895,\n",
      "       0.6402501 , 0.69540218, 0.72228849, 0.67134669, 0.64287084]), 'test_accuracy': array([0.5       , 0.41666667, 0.47916667, 0.46808511, 0.40425532,\n",
      "       0.45833333, 0.41666667, 0.39583333, 0.46808511, 0.40425532,\n",
      "       0.47916667, 0.47916667, 0.5       , 0.36170213, 0.40425532,\n",
      "       0.45833333, 0.375     , 0.39583333, 0.36170213, 0.55319149,\n",
      "       0.5       , 0.45833333, 0.35416667, 0.38297872, 0.46808511,\n",
      "       0.375     , 0.47916667, 0.47916667, 0.34042553, 0.36170213,\n",
      "       0.52083333, 0.375     , 0.39583333, 0.38297872, 0.44680851,\n",
      "       0.45833333, 0.4375    , 0.41666667, 0.40425532, 0.34042553,\n",
      "       0.5       , 0.5       , 0.41666667, 0.42553191, 0.40425532,\n",
      "       0.45833333, 0.52083333, 0.54166667, 0.34042553, 0.44680851,\n",
      "       0.58333333, 0.45833333, 0.47916667, 0.44680851, 0.36170213,\n",
      "       0.4375    , 0.39583333, 0.33333333, 0.44680851, 0.42553191,\n",
      "       0.47916667, 0.4375    , 0.4375    , 0.36170213, 0.31914894,\n",
      "       0.375     , 0.45833333, 0.41666667, 0.34042553, 0.29787234,\n",
      "       0.52083333, 0.39583333, 0.39583333, 0.40425532, 0.38297872,\n",
      "       0.45833333, 0.45833333, 0.47916667, 0.5106383 , 0.44680851,\n",
      "       0.47916667, 0.35416667, 0.41666667, 0.46808511, 0.36170213,\n",
      "       0.45833333, 0.39583333, 0.52083333, 0.38297872, 0.38297872,\n",
      "       0.52083333, 0.52083333, 0.41666667, 0.46808511, 0.36170213,\n",
      "       0.35416667, 0.41666667, 0.4375    , 0.46808511, 0.4893617 ,\n",
      "       0.45833333, 0.4375    , 0.45833333, 0.42553191, 0.31914894,\n",
      "       0.47916667, 0.375     , 0.3125    , 0.53191489, 0.38297872,\n",
      "       0.39583333, 0.47916667, 0.39583333, 0.44680851, 0.36170213,\n",
      "       0.4375    , 0.4375    , 0.33333333, 0.46808511, 0.42553191,\n",
      "       0.4375    , 0.3125    , 0.29166667, 0.57446809, 0.46808511,\n",
      "       0.35416667, 0.375     , 0.4375    , 0.38297872, 0.38297872,\n",
      "       0.45833333, 0.41666667, 0.4375    , 0.36170213, 0.46808511,\n",
      "       0.35416667, 0.54166667, 0.35416667, 0.40425532, 0.46808511,\n",
      "       0.4375    , 0.35416667, 0.41666667, 0.42553191, 0.38297872,\n",
      "       0.41666667, 0.45833333, 0.47916667, 0.44680851, 0.42553191,\n",
      "       0.52083333, 0.52083333, 0.375     , 0.42553191, 0.38297872,\n",
      "       0.45833333, 0.4375    , 0.5       , 0.27659574, 0.44680851,\n",
      "       0.35416667, 0.4375    , 0.45833333, 0.5106383 , 0.42553191,\n",
      "       0.41666667, 0.35416667, 0.39583333, 0.36170213, 0.36170213,\n",
      "       0.5625    , 0.33333333, 0.41666667, 0.34042553, 0.40425532,\n",
      "       0.41666667, 0.39583333, 0.33333333, 0.34042553, 0.4893617 ,\n",
      "       0.3125    , 0.35416667, 0.52083333, 0.46808511, 0.42553191,\n",
      "       0.39583333, 0.35416667, 0.39583333, 0.40425532, 0.34042553,\n",
      "       0.4375    , 0.25      , 0.54166667, 0.36170213, 0.5106383 ,\n",
      "       0.375     , 0.54166667, 0.45833333, 0.5106383 , 0.38297872,\n",
      "       0.5       , 0.41666667, 0.4375    , 0.42553191, 0.29787234,\n",
      "       0.33333333, 0.375     , 0.5       , 0.42553191, 0.44680851,\n",
      "       0.4375    , 0.45833333, 0.39583333, 0.40425532, 0.4893617 ,\n",
      "       0.39583333, 0.41666667, 0.47916667, 0.38297872, 0.38297872,\n",
      "       0.39583333, 0.52083333, 0.41666667, 0.38297872, 0.44680851,\n",
      "       0.4375    , 0.4375    , 0.41666667, 0.44680851, 0.34042553,\n",
      "       0.33333333, 0.4375    , 0.27083333, 0.4893617 , 0.5106383 ,\n",
      "       0.35416667, 0.375     , 0.39583333, 0.40425532, 0.5106383 ,\n",
      "       0.375     , 0.41666667, 0.4375    , 0.46808511, 0.42553191,\n",
      "       0.375     , 0.41666667, 0.5       , 0.40425532, 0.5106383 ,\n",
      "       0.41666667, 0.4375    , 0.375     , 0.53191489, 0.38297872,\n",
      "       0.41666667, 0.41666667, 0.5       , 0.40425532, 0.36170213,\n",
      "       0.3125    , 0.47916667, 0.375     , 0.4893617 , 0.34042553,\n",
      "       0.41666667, 0.5625    , 0.33333333, 0.40425532, 0.40425532,\n",
      "       0.47916667, 0.45833333, 0.33333333, 0.40425532, 0.40425532,\n",
      "       0.33333333, 0.5       , 0.39583333, 0.27659574, 0.38297872,\n",
      "       0.33333333, 0.41666667, 0.33333333, 0.42553191, 0.46808511,\n",
      "       0.52083333, 0.45833333, 0.41666667, 0.53191489, 0.34042553,\n",
      "       0.45833333, 0.5       , 0.45833333, 0.42553191, 0.38297872,\n",
      "       0.41666667, 0.33333333, 0.33333333, 0.44680851, 0.57446809,\n",
      "       0.39583333, 0.4375    , 0.45833333, 0.36170213, 0.40425532,\n",
      "       0.4375    , 0.45833333, 0.39583333, 0.42553191, 0.44680851,\n",
      "       0.4375    , 0.39583333, 0.625     , 0.4893617 , 0.42553191,\n",
      "       0.39583333, 0.45833333, 0.5       , 0.42553191, 0.46808511,\n",
      "       0.5       , 0.35416667, 0.41666667, 0.44680851, 0.42553191,\n",
      "       0.35416667, 0.41666667, 0.375     , 0.46808511, 0.46808511,\n",
      "       0.39583333, 0.25      , 0.5       , 0.31914894, 0.38297872,\n",
      "       0.4375    , 0.375     , 0.39583333, 0.46808511, 0.38297872,\n",
      "       0.33333333, 0.39583333, 0.375     , 0.55319149, 0.31914894,\n",
      "       0.375     , 0.39583333, 0.39583333, 0.40425532, 0.57446809,\n",
      "       0.45833333, 0.41666667, 0.47916667, 0.42553191, 0.42553191,\n",
      "       0.52083333, 0.41666667, 0.5       , 0.34042553, 0.46808511,\n",
      "       0.41666667, 0.41666667, 0.4375    , 0.53191489, 0.31914894,\n",
      "       0.4375    , 0.47916667, 0.45833333, 0.36170213, 0.46808511,\n",
      "       0.41666667, 0.45833333, 0.5       , 0.53191489, 0.38297872,\n",
      "       0.4375    , 0.375     , 0.45833333, 0.44680851, 0.44680851,\n",
      "       0.52083333, 0.41666667, 0.39583333, 0.4893617 , 0.44680851,\n",
      "       0.41666667, 0.35416667, 0.45833333, 0.44680851, 0.40425532,\n",
      "       0.375     , 0.375     , 0.4375    , 0.31914894, 0.40425532,\n",
      "       0.45833333, 0.4375    , 0.39583333, 0.38297872, 0.46808511,\n",
      "       0.375     , 0.4375    , 0.375     , 0.36170213, 0.4893617 ,\n",
      "       0.33333333, 0.375     , 0.41666667, 0.42553191, 0.42553191,\n",
      "       0.39583333, 0.4375    , 0.375     , 0.40425532, 0.55319149,\n",
      "       0.375     , 0.4375    , 0.35416667, 0.42553191, 0.44680851,\n",
      "       0.5       , 0.45833333, 0.33333333, 0.36170213, 0.42553191,\n",
      "       0.29166667, 0.54166667, 0.375     , 0.34042553, 0.55319149,\n",
      "       0.4375    , 0.45833333, 0.39583333, 0.46808511, 0.46808511,\n",
      "       0.5       , 0.45833333, 0.375     , 0.46808511, 0.31914894,\n",
      "       0.47916667, 0.41666667, 0.35416667, 0.31914894, 0.42553191,\n",
      "       0.45833333, 0.52083333, 0.39583333, 0.4893617 , 0.40425532,\n",
      "       0.5       , 0.41666667, 0.35416667, 0.4893617 , 0.36170213,\n",
      "       0.39583333, 0.39583333, 0.47916667, 0.55319149, 0.4893617 ,\n",
      "       0.39583333, 0.39583333, 0.45833333, 0.42553191, 0.42553191,\n",
      "       0.41666667, 0.4375    , 0.4375    , 0.38297872, 0.38297872,\n",
      "       0.25      , 0.39583333, 0.4375    , 0.31914894, 0.5106383 ,\n",
      "       0.45833333, 0.4375    , 0.27083333, 0.46808511, 0.4893617 ,\n",
      "       0.33333333, 0.41666667, 0.45833333, 0.42553191, 0.40425532,\n",
      "       0.45833333, 0.375     , 0.375     , 0.44680851, 0.4893617 ,\n",
      "       0.375     , 0.45833333, 0.4375    , 0.4893617 , 0.29787234,\n",
      "       0.41666667, 0.41666667, 0.35416667, 0.40425532, 0.44680851]), 'train_accuracy': array([0.66315789, 0.68947368, 0.68947368, 0.66492147, 0.70157068,\n",
      "       0.68421053, 0.66315789, 0.68947368, 0.67015707, 0.64921466,\n",
      "       0.63684211, 0.67368421, 0.64210526, 0.7434555 , 0.71204188,\n",
      "       0.71052632, 0.7       , 0.67894737, 0.65968586, 0.66492147,\n",
      "       0.65789474, 0.71052632, 0.66842105, 0.65445026, 0.70680628,\n",
      "       0.73684211, 0.67368421, 0.64736842, 0.69633508, 0.63874346,\n",
      "       0.65789474, 0.71052632, 0.67894737, 0.65968586, 0.68586387,\n",
      "       0.65789474, 0.69473684, 0.67368421, 0.70157068, 0.69109948,\n",
      "       0.63157895, 0.67368421, 0.71052632, 0.72251309, 0.69109948,\n",
      "       0.71578947, 0.65263158, 0.66842105, 0.68062827, 0.67015707,\n",
      "       0.66842105, 0.68947368, 0.67894737, 0.68586387, 0.68062827,\n",
      "       0.67894737, 0.71052632, 0.7       , 0.69109948, 0.67015707,\n",
      "       0.67368421, 0.68421053, 0.71578947, 0.65445026, 0.70680628,\n",
      "       0.66842105, 0.66842105, 0.68947368, 0.65445026, 0.70157068,\n",
      "       0.68421053, 0.69473684, 0.64736842, 0.69109948, 0.68586387,\n",
      "       0.73684211, 0.60526316, 0.67894737, 0.62827225, 0.69633508,\n",
      "       0.66842105, 0.68947368, 0.70526316, 0.64921466, 0.70157068,\n",
      "       0.66842105, 0.62105263, 0.67368421, 0.65968586, 0.71204188,\n",
      "       0.66315789, 0.66315789, 0.66842105, 0.70680628, 0.7434555 ,\n",
      "       0.71052632, 0.68947368, 0.67368421, 0.66492147, 0.68586387,\n",
      "       0.68421053, 0.64736842, 0.64210526, 0.67539267, 0.7486911 ,\n",
      "       0.72105263, 0.62631579, 0.70526316, 0.68062827, 0.70680628,\n",
      "       0.64210526, 0.71052632, 0.68421053, 0.70680628, 0.71204188,\n",
      "       0.68947368, 0.65789474, 0.72631579, 0.64921466, 0.68062827,\n",
      "       0.68947368, 0.70526316, 0.71052632, 0.67015707, 0.65445026,\n",
      "       0.7       , 0.68421053, 0.68421053, 0.72251309, 0.67539267,\n",
      "       0.67368421, 0.67368421, 0.67894737, 0.65968586, 0.65445026,\n",
      "       0.66315789, 0.64210526, 0.68421053, 0.68062827, 0.69109948,\n",
      "       0.66842105, 0.7       , 0.71052632, 0.66492147, 0.67539267,\n",
      "       0.73157895, 0.68421053, 0.66315789, 0.69109948, 0.67539267,\n",
      "       0.64736842, 0.65789474, 0.67368421, 0.70157068, 0.66492147,\n",
      "       0.72105263, 0.69473684, 0.70526316, 0.64921466, 0.67015707,\n",
      "       0.65789474, 0.68421053, 0.7       , 0.67015707, 0.67539267,\n",
      "       0.7       , 0.65789474, 0.69473684, 0.68586387, 0.67539267,\n",
      "       0.67894737, 0.67894737, 0.65263158, 0.70680628, 0.70680628,\n",
      "       0.7       , 0.65789474, 0.69473684, 0.72251309, 0.67539267,\n",
      "       0.68947368, 0.72631579, 0.69473684, 0.67539267, 0.64397906,\n",
      "       0.7       , 0.65789474, 0.68947368, 0.64921466, 0.68062827,\n",
      "       0.68947368, 0.7       , 0.65789474, 0.70680628, 0.66492147,\n",
      "       0.7       , 0.67894737, 0.68421053, 0.66492147, 0.68062827,\n",
      "       0.69473684, 0.68947368, 0.69473684, 0.63350785, 0.68586387,\n",
      "       0.7       , 0.66842105, 0.64736842, 0.67539267, 0.67539267,\n",
      "       0.65789474, 0.68947368, 0.66842105, 0.73298429, 0.65968586,\n",
      "       0.7       , 0.68947368, 0.68421053, 0.69109948, 0.65968586,\n",
      "       0.64736842, 0.65263158, 0.69473684, 0.68062827, 0.67539267,\n",
      "       0.65789474, 0.67894737, 0.71052632, 0.65968586, 0.65968586,\n",
      "       0.70526316, 0.70526316, 0.68947368, 0.65968586, 0.68062827,\n",
      "       0.70526316, 0.66315789, 0.67894737, 0.69109948, 0.63874346,\n",
      "       0.66315789, 0.69473684, 0.66842105, 0.67015707, 0.70157068,\n",
      "       0.66842105, 0.67894737, 0.69473684, 0.70157068, 0.64397906,\n",
      "       0.71052632, 0.66842105, 0.66842105, 0.63350785, 0.66492147,\n",
      "       0.67368421, 0.62631579, 0.67368421, 0.64397906, 0.70680628,\n",
      "       0.67894737, 0.67894737, 0.67894737, 0.67539267, 0.73298429,\n",
      "       0.7       , 0.64210526, 0.69473684, 0.70157068, 0.62827225,\n",
      "       0.68947368, 0.7       , 0.66315789, 0.65968586, 0.65968586,\n",
      "       0.70526316, 0.70526316, 0.68421053, 0.70680628, 0.64921466,\n",
      "       0.67894737, 0.68421053, 0.67894737, 0.65968586, 0.63874346,\n",
      "       0.68947368, 0.68421053, 0.68947368, 0.64397906, 0.68586387,\n",
      "       0.67894737, 0.61578947, 0.67894737, 0.70680628, 0.72774869,\n",
      "       0.66315789, 0.67894737, 0.71578947, 0.67539267, 0.65968586,\n",
      "       0.70526316, 0.7       , 0.66842105, 0.68586387, 0.67015707,\n",
      "       0.66842105, 0.71052632, 0.67894737, 0.65445026, 0.69633508,\n",
      "       0.64736842, 0.66842105, 0.62631579, 0.69109948, 0.70680628,\n",
      "       0.64210526, 0.69473684, 0.68947368, 0.67539267, 0.67539267,\n",
      "       0.67894737, 0.65789474, 0.66842105, 0.64397906, 0.65445026,\n",
      "       0.7       , 0.67368421, 0.66315789, 0.70680628, 0.65445026,\n",
      "       0.7       , 0.69473684, 0.65263158, 0.69109948, 0.63874346,\n",
      "       0.65789474, 0.69473684, 0.68947368, 0.67539267, 0.69109948,\n",
      "       0.72105263, 0.70526316, 0.64736842, 0.67015707, 0.69109948,\n",
      "       0.72105263, 0.66842105, 0.66315789, 0.66492147, 0.62303665,\n",
      "       0.65263158, 0.68421053, 0.67368421, 0.68586387, 0.69109948,\n",
      "       0.66842105, 0.68421053, 0.64736842, 0.68586387, 0.64921466,\n",
      "       0.67368421, 0.66842105, 0.66842105, 0.66492147, 0.69109948,\n",
      "       0.68421053, 0.68947368, 0.67894737, 0.67015707, 0.66492147,\n",
      "       0.70526316, 0.67894737, 0.63684211, 0.68586387, 0.70157068,\n",
      "       0.69473684, 0.71578947, 0.67368421, 0.64921466, 0.71204188,\n",
      "       0.71052632, 0.67894737, 0.71052632, 0.67539267, 0.68062827,\n",
      "       0.66842105, 0.67894737, 0.65263158, 0.69633508, 0.67539267,\n",
      "       0.67894737, 0.68947368, 0.67894737, 0.70680628, 0.69109948,\n",
      "       0.68947368, 0.71578947, 0.70526316, 0.67539267, 0.69109948,\n",
      "       0.67894737, 0.68947368, 0.68947368, 0.67539267, 0.61780105,\n",
      "       0.68947368, 0.63684211, 0.7       , 0.68062827, 0.65968586,\n",
      "       0.65263158, 0.65789474, 0.64736842, 0.65445026, 0.65968586,\n",
      "       0.67894737, 0.66315789, 0.67894737, 0.66492147, 0.69109948,\n",
      "       0.66842105, 0.7       , 0.67368421, 0.69633508, 0.70157068,\n",
      "       0.7       , 0.67894737, 0.68947368, 0.68062827, 0.66492147,\n",
      "       0.65789474, 0.65789474, 0.68421053, 0.69633508, 0.66492147,\n",
      "       0.67368421, 0.72631579, 0.66315789, 0.64921466, 0.72251309,\n",
      "       0.7       , 0.68947368, 0.64210526, 0.72774869, 0.69633508,\n",
      "       0.71578947, 0.67894737, 0.68947368, 0.64921466, 0.67539267,\n",
      "       0.65789474, 0.63684211, 0.7       , 0.68586387, 0.70680628,\n",
      "       0.72631579, 0.66315789, 0.68947368, 0.64397906, 0.66492147,\n",
      "       0.7       , 0.7       , 0.67368421, 0.67015707, 0.65445026,\n",
      "       0.67368421, 0.70526316, 0.67894737, 0.71727749, 0.66492147,\n",
      "       0.72105263, 0.68421053, 0.66842105, 0.68586387, 0.68062827,\n",
      "       0.65789474, 0.65789474, 0.72105263, 0.68586387, 0.70680628,\n",
      "       0.70526316, 0.71052632, 0.64736842, 0.72251309, 0.67015707,\n",
      "       0.66842105, 0.67894737, 0.68421053, 0.63350785, 0.68062827,\n",
      "       0.67368421, 0.66842105, 0.64736842, 0.65968586, 0.69633508,\n",
      "       0.67894737, 0.66842105, 0.72105263, 0.70157068, 0.65445026])} \n",
      "\n",
      "Accuracy mean and variance 0.42285195035460993 0.003744256428090891 \n",
      "\n",
      "F1 macro mean and variance 0.33326894175320126 0.005126034464755357 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=100)\n",
    "\n",
    "#initializing the cross validator with pipe, features, target, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features_cleaned, labels, cv=rkf, scoring=('f1_macro', 'accuracy'), return_train_score=True)\n",
    "\n",
    "#pipe.fit(feat_train, lab_train)\n",
    "#lab_predict = pipe.predict(feat_test)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n",
    "\n",
    "#plt.plot(mlp.loss_curve_)\n",
    "#plt.xlabel('iteration')\n",
    "#plt.ylabel('validation loss')\n",
    "#plt.title(\"MLPClassifier loss curve\")\n",
    "#plt.show()\n",
    "\n",
    "#print the number of misclassified samples, accuracy and complete report (using scikit learn metric tools) \n",
    "#print('Number of mislabeled samples %d out of %d' % ((lab_test != lab_predict).sum(),lab_test.size))\n",
    "#print('Accuracy:',sklearn.metrics.accuracy_score(lab_test, lab_predict))\n",
    "#print(sklearn.metrics.classification_report(lab_test, lab_predict))\n",
    "#print('confusion matrix')\n",
    "#print(sklearn.metrics.confusion_matrix(lab_test,lab_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b78d7f",
   "metadata": {},
   "source": [
    "# Plotting the train and validation learning curves\n",
    "\n",
    "If i take this as a reference: \n",
    "https://towardsdatascience.com/learning-curve-to-identify-overfitting-underfitting-problems-133177f38df5,\n",
    "https://www.datacamp.com/tutorial/tutorial-learning-curves\n",
    "\n",
    "the drop of traing validation from high to lower can be interperted as an underfitting model. This phenonemon indicates that the addition of more training examples can’t improve the model performance on unseen data.\n",
    "\n",
    "Learning curves show the effect of adding more samples during the training process.\n",
    "\n",
    "The test set is used to evaluate the performance of your model.\n",
    "\n",
    "\n",
    "\"My model starts with high accuracy, but then it drops (it starts gaining more loss) as we show it more and more data. Over time. in other words, the addition of more training examples can’t improve the model performance on unseen data.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e436c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=([100, 100, 50, 50]), max_iter=500, activation='identity')\n",
    "\n",
    "#creating scaling object\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(features_cleaned)\n",
    "features_cleaned = scaler.transform(features_cleaned)\n",
    "\n",
    "# dimentionality reduction with LDA (down to 3 features)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(features_cleaned, labels)\n",
    "features_projected = lda.transform(features_cleaned)\n",
    "\n",
    "crossval = RepeatedKFold(n_splits=5, n_repeats=100)\n",
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(mlp, \n",
    "                                                                      features_projected, \n",
    "                                                                      labels, \n",
    "                                                                      cv=crossval, \n",
    "                                                                      scoring=\"accuracy\",\n",
    "                                                                      return_times=True)\n",
    "\n",
    "train_scores = 1-np.mean(train_scores,axis=1)\n",
    "test_scores = 1-np.mean(test_scores,axis=1)\n",
    "\n",
    "#converting the accuracy score to misclassification rate/loss\n",
    "#train_scores = 1-np.mean(train_scores,axis=1)\n",
    "#test_scores = 1-np.mean(test_scores,axis=1)\n",
    "\n",
    "# plot\n",
    "plt.plot(train_sizes, train_scores)\n",
    "plt.plot(train_sizes, test_scores)\n",
    "plt.xlabel('dataset size')\n",
    "#plt.ylabel('misclassification rate/loss')\n",
    "plt.ylabel('accuracy (score)')\n",
    "plt.title(\"MLPClassifier learning curve\")\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
